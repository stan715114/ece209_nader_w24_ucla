{"cells":[{"cell_type":"markdown","metadata":{"id":"n_GnYzq5MvZo"},"source":["# ECE 209 Mobile Security CA 4\n","Implement a simple remote attestation protocol, an attack scenario, and introduce noisy communication to study the impact of network and processing noise.\n"]},{"cell_type":"markdown","metadata":{"id":"DmIhw8iYe39E"},"source":["# Remote Attestation and Response Time"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1709955787864,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"nO0uSagUZGeW"},"outputs":[],"source":["# file path\n","zero_8_path = '/content/zeros_8.txt'\n","attack_8_path = '/content/attack_8.txt'\n","mem_path = '/content/random_numbers_16.txt'\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":559,"status":"ok","timestamp":1709955796815,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"p5EeIsiTMvJX"},"outputs":[],"source":["# verifier function\n","import random\n","from hashlib import sha256\n","\n","# hash function\n","def hash_f (pre_hash, new_line):\n","  text = pre_hash + new_line\n","  return sha256(text.encode('utf-8')).hexdigest()\n","\n","# generate a list of non-repeated nonce in a range of (0,256)\n","def verifier_send_nonce (multi_att):\n","  nonce_list = random.sample(range(257), multi_att)\n","  return nonce_list\n","\n","# verifying process\n","def verifier_end (mem_path, nonce, hash_prover):\n","  hash_verif = hash_f('', nonce)\n","  # hash each line with hash from the previous line\n","  with open(mem_path, 'r') as file:\n","    for line in file:\n","      hash_verif = hash_f(hash_verif, line)\n","  # compare hash value with prover\n","  return 1 if hash_verif == hash_prover else 0\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":546,"status":"ok","timestamp":1709955799588,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"g5z1KNm9MtWb"},"outputs":[],"source":["# prover function\n","from hashlib import sha256\n","\n","# receive nonce and response\n","def prover_end(mem_path, mem_path_2, nonce):\n","  hash_prover = hash_f('', nonce)\n","  # hash each line with hash from the previous line\n","  with open(mem_path, 'r') as file:\n","    for line in file:\n","      hash_prover = hash_f(hash_prover, line)\n","  return hash_prover\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1709955800630,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"aVCdoYBOHWDb","outputId":"8b28df5a-1a53-4563-96fe-7d06b8b8e4b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["attestation run 0, success\n","attestation run 1, success\n","attestation run 2, success\n","attestation run 3, success\n","attestation run 4, success\n","attestation run 5, success\n","attestation run 6, success\n","attestation run 7, success\n","attestation run 8, success\n","attestation run 9, success\n","avg time attestation: 0.0028974802999812256\n"]}],"source":["# remote attestation\n","import time\n","\n","# multi_att : numer of attestation\n","def remote_att(ver_path, pro_path_1, pro_path_2, multi_att, verifier, prover, print_status=1):\n","  # generate a list of non-repeat nonce for multiple attestation\n","  nonce_list = verifier_send_nonce(multi_att)\n","  time_list = []\n","  for index, nonce in enumerate(nonce_list):\n","    time_start = time.perf_counter() # time start\n","    hash_prover = prover(pro_path_1, pro_path_2, str(nonce))\n","    time_end = time.perf_counter() # time end\n","    time_list.append(time_end - time_start)\n","\n","    att_result = verifier(ver_path, str(nonce), hash_prover)\n","    if(print_status):\n","      print(f'attestation run {index}, {(\"success\" if att_result == 1 else \"fail\")}')\n","\n","  return time_list\n","\n","# attestation with 10 times testing\n","att_time = remote_att(mem_path, mem_path, _, 10, verifier_end, prover_end)\n","\n","# avg attestation time\n","print('avg time attestation:', sum(att_time) / len(att_time))"]},{"cell_type":"markdown","metadata":{"id":"fGmK0pJ-e-fl"},"source":["# Malicous_prover Attack and Respond Time"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":244,"status":"ok","timestamp":1709955804533,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"hEA53YLPQC_i","outputId":"0cb6b850-c829-4b56-fe1f-8f3144e234f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["combine file complete.\n","file size: 1600\n"]}],"source":["# pre_compute function.\n","# Replace zero part of f2_file (second half) with non_zero part of f1_text (first half)\n","\n","def pre_compute(file_path_1, file_path_2):\n","  # list of file 1\n","  with open(file_path_1, 'r') as f1:\n","    lines = f1.readlines()\n","    f1_text = [line for line in lines]\n","\n","  # list of file 2\n","  with open(file_path_2, 'r') as f2:\n","    lines = f2.readlines()\n","    f2_text = [line for line in lines]\n","\n","  # combine to new_file\n","  new_file = []\n","  half_size = int(len(f2_text)/2)\n","\n","  for x in range(half_size):\n","    new_file.append(f2_text[x])\n","  for y in range(half_size):\n","    new_file.append(f1_text[y])\n","  print('combine file complete.')\n","\n","  # verify the new file size\n","  print('file size:', len(new_file))\n","\n","  # write out the file\n","  with open('pre_compute.txt', 'w') as file:\n","    for item in new_file:\n","      file.write(item)\n","\n","  # return the pre_compute file as a list\n","  return new_file\n","\n","# computation\n","pre_compute_file = pre_compute(zero_8_path, attack_8_path)\n","pre_compute_path = '/content/pre_compute.txt'\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":662,"status":"ok","timestamp":1709955807195,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"bWnrr8VaDoGm","outputId":"ef58100a-5929-425a-a3e4-e05a0eb8438a"},"outputs":[{"output_type":"stream","name":"stdout","text":["attestation run 0, success\n","attestation run 1, success\n","attestation run 2, success\n","attestation run 3, success\n","attestation run 4, success\n","attestation run 5, success\n","attestation run 6, success\n","attestation run 7, success\n","attestation run 8, success\n","attestation run 9, success\n","avg time malicious attack: 0.0029932494000092904\n"]}],"source":["# malicious prover function\n","from hashlib import sha256\n","\n","def malicous_prover(f1, f2, nonce):\n","  hash_prover = hash_f('', nonce)\n","  # attack_8 file\n","  with open(f1, 'r') as f1:\n","    lines = f1.readlines()\n","    f1_text = [line for line in lines]\n","\n","  # pre_compute file\n","  with open(f2, 'r') as f2:\n","    lines = f2.readlines()\n","    f2_text = [line for line in lines]\n","\n","  # hash the section where pre_compute is diff from attack_8\n","  # the un_overlapping section is zero_8.txt\n","  idx_count = 0\n","  tag = 0\n","  for attack, pre_compute in zip(f1_text, f2_text):\n","    if (attack != pre_compute):\n","      tag = 1\n","    if (tag == 1):\n","      hash_prover = hash_f(hash_prover, pre_compute)\n","      idx_count += 1\n","\n","  for _ in range(idx_count, len(f2_text)):\n","    hash_prover = hash_f(hash_prover, '0\\n')\n","\n","  return hash_prover\n","\n","\n","# attack with attack_8.txt and pre_compute.txt\n","att_time = remote_att(zero_8_path, attack_8_path, pre_compute_path, 10, verifier_end, malicous_prover)\n","\n","# avg attestation time\n","print('avg time malicious attack:', sum(att_time) / len(att_time))"]},{"cell_type":"markdown","metadata":{"id":"Fwl6yLeMfl_T"},"source":["# Verifier Identify Attack with Threshold Response Time"]},{"cell_type":"markdown","metadata":{"id":"OkJZxPcchaNc"},"source":["The way of finding threshold response time."]},{"cell_type":"markdown","metadata":{"id":"euOr6Ni6fhDu"},"source":["The response time begins when the prover receives a nonce and concludes with the prover hashing all lines of the specified mem_file. Given that the verifier has access to the identical mem_file, it's feasible to replicate the entire process on the verifier's side. This enables the collection of multiple response times, allowing for the determination of a threshold by calculating the mean + 4std (4σ), which encompasses 99.9937% of the outputs in a Gaussian distribution. In practice, this procedure is executed 200 times, with each response time being recorded in a time_list. The mean and standard deviation are then computed, and the threshold is established at mean + 4σ."]},{"cell_type":"markdown","metadata":{"id":"1_86hvZlavKa"},"source":["Consequently, the verifier adopts a dynamic threshold instead of a static one, enhancing the defense against similar types of attacks."]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":243,"status":"ok","timestamp":1709957091828,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"1psWmZawfzW0"},"outputs":[],"source":["# verifier with threshold response time\n","import numpy as np\n","import time\n","\n","def verifier_detect(mem_path, nonce, hash_prover, response_time, print_status=1, noise=0):\n","  # verify as normal\n","  ver_result = verifier_end(mem_path, nonce, hash_prover)\n","\n","  # find threshold\n","  # hashing on given mem_file multiple times, 200 times in this case\n","  time_list = []\n","  for _ in range(200):\n","    time_start = time.perf_counter() # time start\n","    hash_verif = hash_f('', nonce)\n","    # hash each line with hash from the previous line\n","    with open(mem_path, 'r') as file:\n","      for line in file:\n","        hash_verif = hash_f(hash_verif, line)\n","    time_end = time.perf_counter() # time end\n","    time_list.append(time_end - time_start)\n","\n","  # plot the list of response time in a gaussian distribution\n","  # take mean+4_sigma as the threshold\n","  mean = np.mean(time_list)\n","  std = np.std(time_list)\n","  thres_time = mean + std * 4\n","  if(print_status):\n","    print('threshold:', thres_time)\n","\n","  # check response time\n","  if (response_time <= thres_time):\n","    return ver_result\n","  else:\n","    return 0\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":238,"status":"ok","timestamp":1709957094909,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"kla9qt0FjBZO"},"outputs":[],"source":["# verifier detection function\n","\n","def detect_att(ver_path, pro_path_1, pro_path_2, multi_att, verifier, prover, print_status=1, noise=0.0):\n","  # generate a list of non-repeat nonce for multiple attestation\n","  nonce_list = verifier_send_nonce(multi_att)\n","  result_list = []\n","  for index, nonce in enumerate(nonce_list):\n","    time_start = time.perf_counter() # time start\n","    hash_prover = prover(pro_path_1, pro_path_2, str(nonce))\n","    time_end = time.perf_counter() # time end\n","    response_time = time_end - time_start\n","\n","    # simulate noisy environment\n","    response_time += noise\n","\n","    att_result = verifier(ver_path, str(nonce), hash_prover, response_time, print_status, noise)\n","    result_list.append(att_result)\n","    if(print_status):\n","      print('response time:', response_time)\n","      print(f'attestation run {index}, {(\"success\" if att_result == 1 else \"fail\")}')\n","      print('-'*20)\n","\n","  return result_list\n"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1709957097667,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"q-ntYqQPdplm"},"outputs":[],"source":["# TP/FP rate calculation\n","\n","def tp_fp_rate(num_list):\n","  p_count = 0\n","  for x in num_list:\n","    if x == 1:\n","      p_count+=1\n","  # rate\n","  p_rate = p_count / len(num_list)\n","  return p_rate"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3553,"status":"ok","timestamp":1709957106582,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"s8i9XQ-geNDx","outputId":"1ee328e9-2739-4f35-fd7c-e3fd3860bb2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["threshold: 0.006638561305918249\n","response time: 0.0024397610000050918\n","attestation run 0, success\n","--------------------\n","threshold: 0.018212537701380267\n","response time: 0.0038428249999924446\n","attestation run 1, success\n","--------------------\n","threshold: 0.005620668722575069\n","response time: 0.0037822179999693617\n","attestation run 2, success\n","--------------------\n","threshold: 0.004416841362775131\n","response time: 0.006233756000028734\n","attestation run 3, fail\n","--------------------\n","threshold: 0.003119398360894042\n","response time: 0.0028326970000307483\n","attestation run 4, success\n","--------------------\n","true positive rate: 0.8\n"]}],"source":["# 5 times with correct prover\n","total_count = 5\n","cor_list = detect_att(mem_path, mem_path, _, total_count, verifier_detect, prover_end)\n","\n","# true positive rate\n","tp_rate = tp_fp_rate(cor_list)\n","print('true positive rate:', tp_rate)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2277,"status":"ok","timestamp":1709957119384,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"_8SGXW1vi4Db","outputId":"934799e7-e981-4a6c-a344-579490687665"},"outputs":[{"output_type":"stream","name":"stdout","text":["threshold: 0.0027185543049858354\n","response time: 0.005153049000000465\n","attestation run 0, fail\n","--------------------\n","threshold: 0.004174881639036963\n","response time: 0.004259133999994447\n","attestation run 1, fail\n","--------------------\n","threshold: 0.003986382278890572\n","response time: 0.0038458390001778753\n","attestation run 2, success\n","--------------------\n","threshold: 0.0034365683679862882\n","response time: 0.0031588930000907567\n","attestation run 3, success\n","--------------------\n","threshold: 0.003551585088459249\n","response time: 0.006652108000025692\n","attestation run 4, fail\n","--------------------\n","false positive rate: 0.4\n"]}],"source":["# 5 times with malicious prover\n","total_count = 5\n","mal_list = detect_att(zero_8_path, attack_8_path, pre_compute_path, total_count, verifier_detect, malicous_prover)\n","\n","# false positive rate\n","fp_rate = tp_fp_rate(mal_list)\n","print('false positive rate:', fp_rate)\n"]},{"cell_type":"markdown","metadata":{"id":"yXloY0JZf4uX"},"source":["# Mimic Noise in Timer"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":232,"status":"ok","timestamp":1709957140070,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"},"user_tz":480},"id":"KxJWoR2JgacH"},"outputs":[],"source":["# random gaussian noise to response time\n","# noise in a order of 10e-3\n","import numpy as np\n","\n","def noisy_att(ver_path, pro_path_1, pro_path_2, verifier, prover):\n","  # the average response time at 0.003s\n","  # expect max_noise = half of avg response time = 0.0015s\n","  max_noise = 0.0015\n","  noise_list = np.linspace(0, max_noise, 10)\n","  for noise in noise_list:\n","    print('noise_level:',noise)\n","    att_list = detect_att(ver_path, pro_path_1, pro_path_2, 50, verifier, prover, 0, noise)\n","    tp_rate = tp_fp_rate(att_list)\n","\n","    # if tp rate drop to 0.5, done\n","    if (tp_rate <= 0.5):\n","      print('Thats it.')\n","      print('Given noise level:', noise)\n","      print('TP rate goes down to:', tp_rate)\n","      return\n","\n","  # if no result from the given noise range\n","  print('noise too low to get tp rate down to 0.5')\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oP5s43pUC_UX","executionInfo":{"status":"ok","timestamp":1709956267316,"user_tz":480,"elapsed":167170,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"}},"outputId":"e21e9247-3839-4c83-e60b-f7583f99ca70"},"outputs":[{"output_type":"stream","name":"stdout","text":["noise_level: 0.0\n","noise_level: 0.00016666666666666666\n","noise_level: 0.0003333333333333333\n","noise_level: 0.0005\n","noise_level: 0.0006666666666666666\n","noise_level: 0.0008333333333333333\n","noise_level: 0.001\n","Thats it.\n","Given noise level: 0.001\n","TP rate goes down to: 0.5\n"]}],"source":["# implement\n","noisy_att(mem_path, mem_path, _, verifier_detect, prover_end)"]},{"cell_type":"markdown","source":["# Improve True Positive Rate in Presence of Noise"],"metadata":{"id":"gF8XdxoDNs19"}},{"cell_type":"markdown","source":["The verifier can preprocess an empty file to collect response times that are corrupted by noise and calculate the noise level that should be subtracted from the response times received from the prover. I collect multiple corrupted response times to calculate the mean + 4*std, treating it as random noise."],"metadata":{"id":"DsobArT6N4g2"}},{"cell_type":"code","source":["# create an empty file\n","with open('empty.txt', 'w') as file:\n","   pass"],"metadata":{"id":"YqpEe7qQTYFd","executionInfo":{"status":"ok","timestamp":1709956332301,"user_tz":480,"elapsed":560,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# modified verifier function\n","\n","import numpy as np\n","import time\n","\n","def verifier_detect_noiseless(mem_path, nonce, hash_prover, response_time, print_status=1, noise=0):\n","  # verify as normal\n","  ver_result = verifier_end(mem_path, nonce, hash_prover)\n","\n","  # preprocess an empty file to estimate noise\n","  noise_list = []\n","  for _ in range(10):\n","    noise_time_start = time.perf_counter()\n","    with open('empty.txt', 'r') as f:\n","      for line in f:\n","        noise_hash = hash_f('','')\n","    noise_time_end = time.perf_counter()\n","    noise_response_time = (noise_time_end - noise_time_start) + noise\n","    noise_list.append(noise_response_time)\n","\n","  # estimate upcoming noise with gaussian distribution\n","  noise_mean = np.mean(noise_list)\n","  noise_std = np.std(noise_list)\n","  noise_expect = noise_mean + noise_std * 4\n","\n","  # find threshold\n","  # hashing on given mem_file multiple times, 200 times in this case\n","  time_list = []\n","  for _ in range(200):\n","    time_start = time.perf_counter() # time start\n","    hash_verif = hash_f('', nonce)\n","    # hash each line with hash from the previous line\n","    with open(mem_path, 'r') as file:\n","      for line in file:\n","        hash_verif = hash_f(hash_verif, line)\n","    time_end = time.perf_counter() # time end\n","    time_list.append(time_end - time_start)\n","\n","  # plot the list of response time in a gaussian distribution\n","  # take mean+4_sigma as the threshold\n","  mean = np.mean(time_list)\n","  std = np.std(time_list)\n","  thres_time = mean + std * 4\n","  if(print_status):\n","    print('threshold:', thres_time)\n","\n","  # check response time\n","  if ((response_time - noise_expect) <= thres_time):\n","    return ver_result\n","  else:\n","    return 0"],"metadata":{"id":"-EVjhwidQVwb","executionInfo":{"status":"ok","timestamp":1709957603797,"user_tz":480,"elapsed":223,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["# implement\n","noisy_att(mem_path, mem_path, _, verifier_detect_noiseless, prover_end)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXfzHAP4V3VP","executionInfo":{"status":"ok","timestamp":1709957844424,"user_tz":480,"elapsed":237965,"user":{"displayName":"ZAN XIE","userId":"13285069241631812713"}},"outputId":"e7f402f6-3c07-4017-c9a3-f0285613619b"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["noise_level: 0.0\n","noise_level: 0.00016666666666666666\n","noise_level: 0.0003333333333333333\n","noise_level: 0.0005\n","noise_level: 0.0006666666666666666\n","noise_level: 0.0008333333333333333\n","noise_level: 0.001\n","noise_level: 0.0011666666666666665\n","noise_level: 0.0013333333333333333\n","noise_level: 0.0015\n","noise too low to get tp rate down to 0.5\n"]}]},{"cell_type":"markdown","source":["The performance does improve. A noise level of 0.0015 seconds is required to lower the TP (True Positive) rate to 0.5, compared to a noise level of 0.001 seconds before."],"metadata":{"id":"6LZyV19SboX3"}}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNFhGRtU2VS1l7tGJKWkfcu"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}